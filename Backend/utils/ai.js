// Backend/utils/ai.js
import OpenAI from "openai";

/* ========= Env seguro ========= */
const OPENAI_API_KEY = (process.env.OPENAI_API_KEY || "").replace(/\s/g, ""); 
const OPENAI_PROJECT = (process.env.OPENAI_PROJECT || "").trim();


function mask(s, keep = 6) {
  if (!s) return "(vac√≠o)";
  return s.length <= keep * 2 ? "***" : s.slice(0, keep) + "‚Ä¶" + s.slice(-keep);
}

// Logs solo para diagn√≥stico (no exponen la clave completa)
console.log("üîë OPENAI_API_KEY:", OPENAI_API_KEY.startsWith("sk-proj-") ? "sk-proj-‚Ä¶" : mask(OPENAI_API_KEY));
console.log("üß© OPENAI_PROJECT:", OPENAI_PROJECT ? mask(OPENAI_PROJECT) : "(sin project)");

if (!OPENAI_API_KEY) {
  console.error("‚ùå Falta OPENAI_API_KEY en el entorno.");
}
if (OPENAI_API_KEY.startsWith("sk-proj-") && !OPENAI_PROJECT) {
  console.error("‚ùå Usas clave de proyecto (sk-proj-‚Ä¶) pero falta OPENAI_PROJECT (proj_‚Ä¶).");
}

/* ========= Cliente OpenAI ========= */
export const openai = new OpenAI({
  apiKey: OPENAI_API_KEY,
  // El SDK requiere 'project' cuando usas claves sk-proj-‚Ä¶
  project: OPENAI_PROJECT || undefined,
});

/* ========= Prompt del sistema ========= */
const SYSTEM_PROMPT_FALLBACK = `
Eres **MiAgro IA**, un asistente agr√≠cola colombiano.

OBJETIVO
- Entregar respuestas **√∫tiles, correctas y accionables** para productores, t√©cnicos y tomadores de decisi√≥n.
- Prioriza **sostenibilidad**, **seguridad** y **buenas pr√°cticas locales (MIP)**.

ESTILO
- Responde **siempre en espa√±ol**.
- S√© **claro** y **amable**. Explica lo necesario sin rodeos.
- Usa **listas numeradas** para recomendaciones y **negritas** para lo crucial.
- Cuando ayude, usa **tablas Markdown** compactas.
- Evita p√°rrafos largos. Divide en secciones cortas con t√≠tulos breves.

RIGOR Y ALCANCE
- No inventes **precios** ni **clima**. Si faltan datos, dilo y sugiere d√≥nde verificarlos (p.ej., IDEAM, ICA, MinAgricultura, bolsas/centrales de abasto locales).
- Si la consulta requiere **contexto** (municipio, cultivo, fecha, fase fenol√≥gica, escala del lote), **p√≠delo** expl√≠citamente en 1‚Äì2 preguntas.
- Prefiere recomendaciones **MIP** y **bajo riesgo**; advierte contra pr√°cticas prohibidas o peligrosas.
- Si hay **incertidumbre**, ind√≠cala y ofrece **supuestos razonables**.

FORMATO DE SALIDA
1) **Resumen** (2‚Äì4 vi√±etas con la idea central).
2) **Pasos pr√°cticos** (1., 2., 3.).
3) **Detalles/explicaci√≥n** (si aporta valor).
4) **Siguientes datos a aportar** (si faltan).
5) **Fuentes** (solo cuando uses informaci√≥n externa espec√≠fica).

TABLAS (cuando aplique)
- Usa encabezados claros y pocas columnas. Ej.: \`| Pr√°ctica | Cu√°ndo | Nota |\`.

REGLAS
- No compartas informaci√≥n que ponga en riesgo a personas/animales/ambiente.
- Mant√©n un tono **constructivo** y evita juicios.
- Si el usuario pide algo fuera del dominio, ayuda con l√≠mites razonables.

EJECUCI√ìN
- Antes de responder, identifica: **cultivo**, **ubicaci√≥n**, **ventana temporal**, **objetivo**.
- Ajusta la recomendaci√≥n a ese contexto; si falta, **pregunta**.
`.trim();

/* ========= Builder de mensajes ========= */
function buildMessages({ history = [], userText, context = {} }) {
  const sysFromEnv = (process.env.MIAGRO_SYSTEM_PROMPT || "").trim();
  const systemPrompt = [
    sysFromEnv || SYSTEM_PROMPT_FALLBACK,
    context?.municipio ? `\nContexto: Municipio: ${context.municipio}.` : "",
    context?.departamento ? ` Departamento: ${context.departamento}.` : "",
    context?.cultivo ? ` Cultivo: ${context.cultivo}.` : "",
  ]
    .join("")
    .trim();

  const messages = [];
  if (history.length && history[0]?.role === "system") {
    messages.push(...history);
  } else {
    messages.push({ role: "system", content: systemPrompt });
    messages.push(...history);
  }
  if (userText) messages.push({ role: "user", content: userText });

  const MAX_MSGS = 24;
  return messages.slice(-MAX_MSGS);
}

/* ========= Llamada al modelo con manejo de errores ========= */
export async function askOpenAI(
  messagesOrParams,
  opts = { temperature: 0.3, model: "gpt-4o-mini", max_tokens: 900 }
) {
  if (!OPENAI_API_KEY) {
    const e = new Error("Falta OPENAI_API_KEY.");
    e.status = 500;
    throw e;
  }
  if (OPENAI_API_KEY.startsWith("sk-proj-") && !OPENAI_PROJECT) {
    const e = new Error("Falta OPENAI_PROJECT para clave de proyecto.");
    e.status = 500;
    throw e;
  }

  let messages;
  if (Array.isArray(messagesOrParams)) {
    const hasSystem = messagesOrParams[0]?.role === "system";
    messages = hasSystem
      ? messagesOrParams
      : [{ role: "system", content: SYSTEM_PROMPT_FALLBACK }, ...messagesOrParams];
  } else {
    messages = buildMessages(messagesOrParams || {});
  }

  try {
    const resp = await openai.chat.completions.create({
      model: opts?.model ?? "gpt-4o-mini",
      temperature: opts?.temperature ?? 0.3,
      max_tokens: opts?.max_tokens ?? 900,
      messages,
    });
    return resp.choices?.[0]?.message?.content?.trim() || "";
  } catch (err) {
    const status = err?.status || err?.response?.status;
    // Sanitiza el error para no exponer mensajes de OpenAI al frontend
    if (status === 401 || status === 403) {
      const e = new Error("Credenciales de OpenAI inv√°lidas o faltantes.");
      e.status = 502;
      throw e;
    }
    const e = new Error("Error llamando al modelo de OpenAI.");
    e.status = 502;
    throw e;
  }
}

export { buildMessages };
